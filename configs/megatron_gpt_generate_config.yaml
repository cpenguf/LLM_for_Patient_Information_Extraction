name: nemo_gpt_generate

trainer:
  devices: 1
  accelerator: gpu
  num_nodes: 1
  precision: 16
  logger: false
  enable_checkpointing: false
  use_distributed_sampler: false

model:
  restore_from_path: ??? # set to a Llama 3.1 or GatorTronLlama .nemo checkpoint
  tensor_model_parallel_size: 1
  pipeline_model_parallel_size: 1
  context_parallel_size: 1
  micro_batch_size: 1
  global_batch_size: 1
  seq_length: 4096
  tokens_to_generate: 128
  temperature: 0.7
  top_k: 50
  top_p: 0.9
  all_probs: false
  compute_attention_mask: true
  add_BOS: false
  add_EOS: true
  greedy: false
  repetition_penalty: 1.1
  min_tokens_to_generate: 1
  stop_after_sentence: false
  random_seed: 1234
  iteration_count: 1
  inference_micro_batch_size: 1
  hold_on_cuda: false
  output_file: outputs/inference/predictions.jsonl
  samples_to_generate: null

inference:
  prompts: [] # list of strings; can be overridden with command line
  prompts_file: null # path to a JSONL with {"input": "..."} lines; if set, overrides `prompts`
